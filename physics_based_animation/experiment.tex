\documentclass{fancydoc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{todonotes}
%\hypersetup{
%	colorlinks=true,
%	linkcolor=blue,
%	filecolor=magenta,      
%	urlcolor=cyan,
%}

\newtheorem{mydef}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{note}{Note}
\newtheorem{ex}{Example}

\newcommand{\trans}{\mathrm{T}}
\newcommand{\diffd}{\mathrm{d}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}

\title{Physics-based Animation: A Mathematical Perspective}
\author{Based on Ladislav Kavan's CS6660 with annotations from wxgopher}

\maketitle
\tableofcontents
\newpage
{\large This lecture note is based on Dr. Ladislav Kavan's Physics-based Animation course CS6660, originally taught at the University of Utah. I also try to include some supplementary materials from other resources.}


{\large Warning: Although as I strive to make this material useful, there are certain bugs, use this material at your own risk. I would also be grateful to hear \href{mailto:wxguojlu@gmail.com}{feedbacks}.}

\dotfill

\section{Classical Mechanics}

\subsection{Basics: a harmonic oscillator}

\section{Time Integration}

\section{Optimization}
\subsection{Implicit Newmark}

\begin{subequations}
	\begin{align}
	x_{n+1} &= x_n + \frac{h}{2}(v_n + v_{n+1}),\\
	v_{n+1} &= v_n = \frac{h}{2}(f_n + f_{n+1}),
	\end{align}
\end{subequations}
where $x$ and $v$ are positions and velocities, and $f_n \equiv f(x_n)$. Thus we have
\begin{equation}\label{secoptim:nw_eq}
x_{n+1} - x_n - hv_n = \frac{h^2}{4}(f_n + f_{n+1}).
\end{equation}

Let $y = x_n + h_nv_n + \frac{h^2}{4}f_n$, $x_{n+1} = x$, note that $\nabla E = -f$, then \eqref{secoptim:nw_eq} becomes

\begin{equation}
x - y = \frac{h^2}{4}f \Rightarrow x - y + \frac{h^2}{4}f\nabla E = 0.
\end{equation}

Let $g(x) = \frac{1}{2}\Vert x-y\vert^2 + \frac{h^2}{4}E$, then solving $g$ equals to solve $x$ for
\begin{equation}
\min_{x} \quad g(x).
\end{equation}

\subsection{Optimization Problems}
Problem formulation:
\begin{equation}\label{problem_optim_nonlinear}
\min_{_x} \quad g(x), \quad x\in \!R^n, \quad g\in \!R.
\end{equation}

Optimization problems can be categorized into constrained or unconstrained problems, or convex or non-convex problems. 

\begin{thm}
	For a convex problem (where both objective and feasible set are convex), if the objective is $\!C^2$, then the Hessian $H \succeq 0$, and the local minimum is the global minimum.
\end{thm}

\begin{mydef}
	A \textbf{linear programming (LP)} is a problem with linear objective and linear equality or inequality constraints. A \textbf{quadratic programming (QP)} is {\bf the same as LP} except with a quadratic objective.
\end{mydef}

\begin{note}
	Convex QP has polynomial time solver but non-convex QP is NP-hard.
\end{note}
\begin{ex}
	A non-convex QP: 
	\begin{subequations}
		\begin{align}
		\min_{x} \quad&\frac{1}{2} \Vert Ax \Vert^2, \\
		s.t. \quad & \Vert x \Vert_2 = 1.
		\end{align}
	\end{subequations}
\end{ex}
\begin{note}
	Software package for solving non-convex problem: {\rm IpOPT}, {\rm KNITRO}, or \href{https://neos-guide.org/}{NEOS-Guide} 
\end{note}

\subsubsection{Solving unconstrained problems}
There are two ways to solve an unconstrained problem: descent method or trust-region method.

Descent method refers to pick a descent direction $d$ and do an exact or inexact line search~(LS) to determine descent distance $\alpha d$.
\bigbreak
\begin{mydef}
	\textbf{Descent direction}: $\forall \alpha \in (0, \alpha_0)$, $\alpha_0 > 0$, $g(x+\alpha d) < g(x)$.
\end{mydef}
\begin{mydef}
	\textbf{Exact LS} refers to solving the following problem:
	\begin{equation*}
	\argmin_{\alpha>0} g(x+\alpha d).
	\end{equation*}
\end{mydef}
\todo[inline]{Backtracking LS}

\subsubsection{Newton's method}
A usual descent direction is called \textbf{gradient descent}~(GD), denoted by $d=-\nabla g$. It doesn't work well sometime, for example:
\begin{ex}
	\begin{equation}
	\min_{x_1, x_2} g(x1, x2) = \frac{1}{2}(x_1^2 + \gamma x_2^2), \quad \gamma > 0.
	\end{equation}
\end{ex}
If we do exact LS, we get
\begin{subequations}
\begin{align}
x_1^k &= \gamma (\frac{\gamma - 1}{\gamma + 1})^k, \\
x_2^k &= (-\frac{\gamma - 1}{\gamma + 1})^k.
\end{align}
\end{subequations}
If gamma becomes huge, we can tell GD converges slowly (as two GD directions are perpendicular).
\bigbreak 

Newton's method refers to do a quadratic approximation to problem~\eqref{problem_optim_nonlinear}, given by
\begin{equation}\label{newton_approximation}
g(x + p) = g(x) + \nabla g^{\trans}(x)p + \frac{1}{2}p^\trans\nabla^2g(x)p + O(\Vert p\Vert^2) \equiv \tilde{g}(x) + O.
\end{equation}
Thus we have
\begin{equation*}
\frac{\partial \tilde{g}}{\partial p} = 0 \Longleftrightarrow \nabla g + \nabla^2 gp = 0.
\end{equation*}
The \textbf{Newton descent direction} is given by
\begin{equation}\label{newton_descent_direction}
p = -(\nabla^2g)^{-1}\nabla g.
\end{equation}
\bigbreak
\begin{note}
	Newton's method is affine invariant. Let $x=Ty$ with $T$ being a nonsingular matrix, so problem~\eqref{problem_optim_nonlinear} is equivalent to problem 
	\begin{equation}
	\min_{y} \tilde{g}(y).
	\end{equation}
	We also have 
	\begin{equation*}
	\nabla \tilde{g} = T^2 \nabla g, \quad \nabla^2 \tilde{g} = T^
	\trans \nabla^2 g T.
	\end{equation*}
	Newton direction $\Delta y$ of $\tilde{g}$ and $\Delta x$ of $g$ is given by
	\begin{equation*}
	\Delta y = -T^{-1}\nabla^2 g \nabla g = T^{-1} \Delta x.
	\end{equation*}
\end{note}

\begin{mydef}
	\textbf{Newton decrement}: substitute Newton descent direction~\eqref{newton_descent_direction} into~\eqref{newton_approximation}, we get the \textbf{Newton decrement} 
	\begin{equation}
	\lambda^2 = g - \frac{1}{2}\nabla g^\trans(\nabla^2 g)^{-1}\nabla g.
	\end{equation} 
	A stopping criteria for Newton's method would be
	\begin{equation*}
	\frac{\lambda^2}{2} \leq \epsilon.
	\end{equation*}
	Note that Newton decrement is also affine invariant.
\end{mydef}
\bigbreak 

Convergence analysis of the Newton's method is given as follows:
\begin{thm}
\textbf{Kantorovich}: if $g$ is strictly convex and $\nabla^2 g$ is Lipschitz continuous, then $\exists \epsilon > 0, \eta > 0, \gamma > 0$, s.t.
\begin{description}
	\item[Damped phase I] If $\Vert\nabla g \Vert \geq \eta$, then $\Vert g^{k+1} \Vert \leq \Vert g^{k} \Vert - \gamma$;
	\item[Quadratic phase II] If $\Vert\nabla g \Vert < \eta$, then $\Vert g^{k+1} \Vert \leq c \Vert g^{k}\Vert^2$.
\end{description}
\end{thm}
Some cases where Newton's method doesn't work well:
\begin{enumerate}
	\item If $g$ is highly nonlinear, the damped phase will be long;
	\item If $g$ is non-convex, solution might not converge to a minimum.
\end{enumerate}
In practical implementations, the Hessian might not always be positive definite. A possible Hessian modification is:
\begin{note}
	\textbf{Hessian modification}: Consider $A = \nabla^2 g + cI$, where $c>0$. It is shown that if $\nabla^2 g = Q\Lambda Q^\trans$ ($\nabla^2 g$ is symmetric, hence it is always diagonalizable), then $A=Q(\Lambda + cI)Q^\trans$, hence $A$ is positive definite given sufficiently large $c>0$. 
\end{note}

Solving Newton's direction~\eqref{newton_descent_direction} refers to solving a linear system. We introduce several techniques to tackle this.

\subsection{Numerical Linear Algebra}
We consider solving a linear system $Ax = b$.
\subsubsection{Direct solvers}
We can prefactor $A$ into $A = UV^\trans$, with $U$ and $V$ being low rank matrices.

Common factorization methods are
\begin{description}
	\item[LU] If $A$ is nonsingular, then there exist $L,P,U$, where they are lower-triangular matrix, permutation matrix (hence orthogonal), and upper-triangular matrix, respectively, s.t. $A=PLU$.
	\item[Sparse LU] $A=P_1LUP_2$, where $P_1$ and $P_2$ are permutations to utilize sparse information of $A$.
	\item[Cholesky] For symmetric positive-definite matrix, we have $A = LL^\trans$ with unique $L$. Note that for positive semi-definite matrix, Cholesky is not unique.
\end{description}
 \todo[inline]{LDLT}
 
\subsubsection{Iterative solvers}
Iterative solvers includes:
\begin{enumerate}
	\item Classical method: Jacobian, Gauss-Seidel, SOR~(super over-relaxation), etc.;
	\item Krylov subspace method: CG~(conjugate gradient)\footnote{A good reference on CG is~\cite{shewchuk1994introduction}.}, GMRES~(generalized minimal residual), etc.;
	\item multigrid method.
\end{enumerate}

\paragraph{Classical method}
Suppose $P$ is easy to invert, let $A = P+A-P$, then
\begin{equation*}
Ax=b \quad \Leftrightarrow \quad Px = (P-A)x + b.
\end{equation*} 
$P = diag(A)$ gives us Jacobian method, and it's GPU-friendly; $P = lower(A)$ gives us GS method; $P = diag(A) + w\cdot lower(A)$ gives us SOR method where $w<2$.

The residual term follows
\begin{equation*}
r_k \equiv A(x^\star - x_k) = b - Ax_k \quad \Leftrightarrow \quad r_{k+1} = (I-P^{-1}A)r_k.
\end{equation*}
To make classical method converge, we need $\rho(I - P^{-1}A) < 1$, where $\rho(\cdot)$ is the spectrum radius.

\paragraph{Krylov subpace method}


Assuming $A^\trans = A$ and $A \succeq 0$, then
\begin{equation}\label{cg_form}
\argmin_{x} g(x) = \frac{1}{2} x^\trans Ax - x^\trans b \quad \Leftrightarrow \quad solve\,\, Ax=b.
\end{equation}
Let $\nabla g_k = Ax_k - b = -r_k$\footnote{$Ax$ is computed on-fly, we don't need the whole $A$.} as a descent direction, the line search for~\eqref{cg_form} is as follows:
\begin{enumerate}
	\item Solve $\alpha$ from $\argmin_{\alpha} (\frac{1}{2} (x + \alpha r)^\trans A (x + \alpha r) - (x + \alpha r)^\trans b \equiv \frac{1}{2} \Vert x + \alpha r \Vert^2_{A} - (x+\alpha r)^\trans b)$ by letting $\frac{\partial E}{\partial \alpha} = 0$, where $E$ is the objective;
	\item $\alpha$ follows $\alpha = -\frac{\Vert r \Vert^2}{\vert r \Vert^2_A}$;
	\item $x_{k+1} = x_k + \alpha_k r_k$.
\end{enumerate}
This is the gist of CG from gradient descent.

\subparagraph{CG}
Assuming solving problem~\eqref{cg_form}.
\begin{mydef}
	\textbf{A-conjugate} A set of vectors $\{p_i\}$ are A-conjugate iff $\forall  i, j, i\neq j, p_i^\trans Ap_j = 0$.
\end{mydef}
The CG algorithm is as follows:
\begin{enumerate}
	\item We define $r_k = Ax_k - b$;
	\item Let $p_1 = r_1$\footnote{$r_1$ is usually chosen as a GD step};
	\item $p_k = r_k + \beta_k p_{k-1}, \beta_k = \frac{r_k^\trans Ap_{k-1}}{p_{k-1}^\trans Ap_{k-1}}$;
	\item Do LS along direction $p_k$, we have $\alpha_k = \frac{r_k^\trans p_k}{p^\trans A p_k}$;
	\item $x_{k+1} = x_k + \alpha_k p_k$.
\end{enumerate}

\subparagraph{Preconditioning CG}
If $A$ is ill-conditioned, we consider adding preconditioner $M$ to $A$, s.t. $cond(MA) < cond(A)$.

The Jacobian preconditioner is given by $M = diag(A)^{-1}$. The incomplete Cholesky is given by prefactoring $A$ into $L_a L_a^\trans$ where -$L_a$ is an approximation of $L$ of the Cholesky decomposition of $A$ given by $A=LL^\trans$.

\section{Elastic Materials and Finite Element Simulation}
Consider kinetic energy 
\begin{equation*}
k = \frac{1}{2} v^\trans Mv.
\end{equation*}
Assuming unit mass, we have
\begin{equation}
k = \frac{1}{2} \int_\Omega \rho(p) \Vert v(p) \Vert^2 \diffd p,
\end{equation}
where $p \in \Omega$ is the material point. We discretize $\Omega$, and for every node $p_i$ we define piece-wise shape function $s_i : \Omega \mapsto [0, 1]$, s.t. $\sum_i s_i = 1$. For every region $E_t$, we also define
\[r_t(p) = \begin{cases}
1 & p\in E_t,\\
0 & otherwise.
\end{cases} 
\]

We have
\begin{subequations}
\begin{align}
v(p) &=\sum_i v_i s_i(p), \\
\rho(p) &= \sum_t \rho_t r_t(p).
\end{align}
\end{subequations}
The kinetic energy follows
\begin{subequations}
	\begin{align}
	k &= \frac{1}{2} \int_\Omega \sum_t \rho_t r_t \Vert v(p)\Vert^2 \diffd p\\
	  &= \frac{1}{2} \sum_t \rho_t \int_\Omega r_t(p) \Vert v(p) \Vert^2 \diffd p\\
	  &= \frac{1}{2} \sum_t \rho_t \int_{E_t} \Vert v \Vert^2 \diffd p \\
	  &= \frac{1}{2} \sum_t \rho_t \sum_{i,j} v_i^\trans v_j \int_{E_t} s_i s_j \diffd p.\\
	\end{align}
\end{subequations}
We define
\begin{equation}
\int_{E_t} s_i s_j \diffd p = s_{i, j}^t,
\end{equation}
for different methods of discretization, we have
\begin{description}
	\item[Triangal element~(2-dimension)] \[s^t_{i,j} = \begin{cases}
	\frac{Area(t)}{6} & i = j, \\
	\frac{Area(t)}{12} & i \neq j.
	\end{cases}\]
	\item[Tetrahderal element~(3-dimension)] \[s^t_{i,j} = \begin{cases}
	\frac{Area(t)}{10} & i = j, \\
	\frac{Area(t)}{20} & i \neq j.
	\end{cases}\]
\end{description}

Let's consider practical implementation of FEM. From discussions above, we have
\begin{subequations}
	\begin{align}
	\int_{E_t} \Vert v(p) \Vert^2 \diffd p &= \sum_{i, j}v_i^\trans v_j \int_{E_t} s_i s_j \diffd p\\
	&= \sum_{i, j}v_i^\trans v_j  s^t_{i,j} \\ 
	&= V^\trans S_t V,
	\end{align}
\end{subequations}
where $V = (v_1, v_2, \cdots, v_n)^\trans$, and
\begin{equation*}
S_t = \begin{pmatrix}
s_{1,1}^t \cdot I_3  & \cdots & s^t_{1,n} \cdot I_3 \\
\vdots & \ddots & \vdots \\
s_{n, 1}^t \cdot I_3 & \cdots & s^t_{n,n} \cdot I_3 \\
\end{pmatrix}.
\end{equation*}

\section{Fluids and Partial Differential Equations}

\section{Something more...}

\section{Papers and books}

Numerical optimization can refer to~\cite{boyd2004convex}~\cite{nocedal2006numerical}.

\cite{bonet1997nonlinear} is a great reference for continuum mechanics and FEM.

An awesome book on fluids simulation is~\cite{bridson2015fluid}.

Vector calculus can be found in~\cite{petersen2008matrix}.

\bibliographystyle{plain}
\bibliography{bib.bib} 

\end{document}