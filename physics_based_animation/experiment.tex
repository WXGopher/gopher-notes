\documentclass{fancydoc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{todonotes}
%\hypersetup{
%	colorlinks=true,
%	linkcolor=blue,
%	filecolor=magenta,      
%	urlcolor=cyan,
%}

\newtheorem{mydef}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{note}{Note}
\newtheorem{ex}{Example}

\newcommand{\trans}{\mathrm{T}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}

\title{Ladislav Kavan's Physically Based Simulation 2017ed}
\author{Edited by wxgopher}

\maketitle
\tableofcontents
\newpage
{\large This lecture note is based on Dr. Ladislav Kavan's Physics-based Animation course CS6660, originally taught at the University of Utah. I also try to include some supplementary materials from other resources.}


{\large Warning: Although as I strive to make this material useful, there are certain bugs, use this material at your own risk. I would also be grateful to hear \href{mailto:wxguojlu@gmail.com}{feedbacks}.}

\dotfill

\section{Classical Mechanics}

\subsection{Basics: a harmonic oscillator}

\section{Time Integration}

\section{Optimization}
\subsection{Implicit Newmark}

\begin{subequations}
	\begin{align}
	x_{n+1} &= x_n + \frac{h}{2}(v_n + v_{n+1}),\\
	v_{n+1} &= v_n = \frac{h}{2}(f_n + f_{n+1}),
	\end{align}
\end{subequations}
where $x$ and $v$ are positions and velocities, and $f_n \equiv f(x_n)$. Thus we have
\begin{equation}\label{secoptim:nw_eq}
x_{n+1} - x_n - hv_n = \frac{h^2}{4}(f_n + f_{n+1}).
\end{equation}

Let $y = x_n + h_nv_n + \frac{h^2}{4}f_n$, $x_{n+1} = x$, note that $\nabla E = -f$, then \eqref{secoptim:nw_eq} becomes

\begin{equation}
x - y = \frac{h^2}{4}f \Rightarrow x - y + \frac{h^2}{4}f\nabla E = 0.
\end{equation}

Let $g(x) = \frac{1}{2}\Vert x-y\vert^2 + \frac{h^2}{4}E$, then solving $g$ equals to solve $x$ for
\begin{equation}
\min_{x} \quad g(x).
\end{equation}

\subsection{Optimization Problems}
Problem formulation:
\begin{equation}\label{problem_optim_nonlinear}
\min_{_x} \quad g(x), \quad x\in \!R^n, \quad g\in \!R.
\end{equation}

Optimization problems can be categorized into constrained or unconstrained problems, or convex or non-convex problems. 

\begin{thm}
	For a convex problem (where both objective and feasible set are convex), if the objective is $\!C^2$, then the Hessian $H \succeq 0$, and the local minimum is the global minimum.
\end{thm}

\begin{mydef}
	A \textbf{linear programming (LP)} is a problem with linear objective and linear equality or inequality constraints. A \textbf{quadratic programming (QP)} is {\bf the same as LP} except with a quadratic objective.
\end{mydef}

\begin{note}
	Convex QP has polynomial time solver but non-convex QP is NP-hard.
\end{note}
\begin{ex}
	A non-convex QP: 
	\begin{subequations}
		\begin{align}
		\min_{x} \quad&\frac{1}{2} \Vert Ax \Vert^2, \\
		s.t. \quad & \Vert x \Vert_2 = 1.
		\end{align}
	\end{subequations}
\end{ex}
\begin{note}
	Software package for solving non-convex problem: {\rm IpOPT}, {\rm KNITRO}, or \href{https://neos-guide.org/}{NEOS-Guide} 
\end{note}

\subsubsection{Solving unconstrained problems}
There are two ways to solve an unconstrained problem: descent method or trust-region method.

Descent method refers to pick a descent direction $d$ and do an exact or inexact line search~(LS) to determine descent distance $\alpha d$.
\bigbreak
\begin{mydef}
	\textbf{Descent direction}: $\forall \alpha \in (0, \alpha_0)$, $\alpha_0 > 0$, $g(x+\alpha d) < g(x)$.
\end{mydef}
\begin{mydef}
	\textbf{Exact LS} refers to solving the following problem:
	\begin{equation*}
	\argmin_{\alpha>0} g(x+\alpha d).
	\end{equation*}
\end{mydef}
\todo[inline]{Backtracking LS}

\subsubsection{Newton's method}
A usual descent direction is called \textbf{gradient descent}~(GD), denoted by $d=-\nabla g$. It doesn't work well sometime, for example:
\begin{ex}
	\begin{equation}
	\min_{x_1, x_2} g(x1, x2) = \frac{1}{2}(x_1^2 + \gamma x_2^2), \quad \gamma > 0.
	\end{equation}
\end{ex}
If we do exact LS, we get
\begin{subequations}
\begin{align}
x_1^k &= \gamma (\frac{\gamma - 1}{\gamma + 1})^k, \\
x_2^k &= (-\frac{\gamma - 1}{\gamma + 1})^k.
\end{align}
\end{subequations}
If gamma becomes huge, we can tell GD converges slowly (as two GD directions are perpendicular).
\bigbreak 

Newton's method refers to do a quadratic approximation to problem~\eqref{problem_optim_nonlinear}, given by
\begin{equation}\label{newton_approximation}
g(x + p) = g(x) + \nabla g^{\trans}(x)p + \frac{1}{2}p^\trans\nabla^2g(x)p + O(\Vert p\Vert^2) \equiv \tilde{g}(x) + O.
\end{equation}
Thus we have
\begin{equation*}
\frac{\partial \tilde{g}}{\partial p} = 0 \Longleftrightarrow \nabla g + \nabla^2 gp = 0.
\end{equation*}
The \textbf{Newton descent direction} is given by
\begin{equation}\label{newton_descent_direction}
p = -(\nabla^2g)^{-1}\nabla g.
\end{equation}
\bigbreak
\begin{note}
	Newton's method is affine invariant. Let $x=Ty$ with $T$ being a nonsingular matrix, so problem~\eqref{problem_optim_nonlinear} is equivalent to problem 
	\begin{equation}
	\min_{y} \tilde{g}(y).
	\end{equation}
	We also have 
	\begin{equation*}
	\nabla \tilde{g} = T^2 \nabla g, \quad \nabla^2 \tilde{g} = T^
	\trans \nabla^2 g T.
	\end{equation*}
	Newton direction $\Delta y$ of $\tilde{g}$ and $\Delta x$ of $g$ is given by
	\begin{equation*}
	\Delta y = -T^{-1}\nabla^2 g \nabla g = T^{-1} \Delta x.
	\end{equation*}
\end{note}

\begin{mydef}
	\textbf{Newton decrement}: substitute Newton descent direction~\eqref{newton_descent_direction} into~\eqref{newton_approximation}, we get the \textbf{Newton decrement} 
	\begin{equation}
	\lambda^2 = g - \frac{1}{2}\nabla g^\trans(\nabla^2 g)^{-1}\nabla g.
	\end{equation} 
	A stopping criteria for Newton's method would be
	\begin{equation*}
	\frac{\lambda^2}{2} \leq \epsilon.
	\end{equation*}
	Note that Newton decrement is also affine invariant.
\end{mydef}
\bigbreak 

Convergence analysis of the Newton's method is given as follows:
\begin{thm}
\textbf{Kantorovich}: if $g$ is strictly convex and $\nabla^2 g$ is Lipschitz continuous, then $\exists \epsilon > 0, \eta > 0, \gamma > 0$, s.t.
\begin{description}
	\item[Damped phase I] If $\Vert\nabla g \Vert \geq \eta$, then $\Vert g^{k+1} \Vert \leq \Vert g^{k} \Vert - \gamma$;
	\item[Quadratic phase II] If $\Vert\nabla g \Vert < \eta$, then $\Vert g^{k+1} \Vert \leq c \Vert g^{k}\Vert^2$.
\end{description}
\end{thm}
Some cases where Newton's method doesn't work well:
\begin{enumerate}
	\item If $g$ is highly nonlinear, the damped phase will be long;
	\item If $g$ is non-convex, solution might not converge to a minimum.
\end{enumerate}
In practical implementations, the Hessian might not always be positive definite. A possible Hessian modification is:
\begin{note}
	\textbf{Hessian modification}: Consider $A = \nabla^2 g + cI$, where $c>0$. It is shown that if $\nabla^2 g = Q\Lambda Q^\trans$ ($\nabla^2 g$ is symmetric, hence it is always diagonalizable), then $A=Q(\Lambda + cI)Q^\trans$, hence $A$ is positive definite given sufficiently large $c>0$. 
\end{note}

Solving Newton's direction~\eqref{newton_descent_direction} refers to solving a linear system. We introduce several techniques to tackle this.

\subsection{Numerical Linear Algebra}
We consider solving a linear system $Ax = b$.
\subsubsection{Direct solvers}
We can prefactor $A$ into $A = UV^\trans$, with $U$ and $V$ being low rank matrices.

Common factorization methods are
\begin{description}
	\item[LU] If $A$ is nonsingular, then there exist $L,P,U$, where they are lower-triangular matrix, permutation matrix (hence orthogonal), and upper-triangular matrix, respectively, s.t. $A=PLU$.
	\item[Sparse LU] $A=P_1LUP_2$, where $P_1$ and $P_2$ are permutations to utilize sparse information of $A$.
	\item[Cholesky] For symmetric positive-definite matrix, we have $A = LL^\trans$ with unique $L$. Note that for positive semi-definite matrix, Cholesky is not unique.
\end{description}
 \todo[inline]{LDLT}
 
\subsubsection{Iterative solvers}
Iterative solvers includes:
\begin{enumerate}
	\item Classical method: Jacobian, Gauss-Seidel, SOR~(super over-relaxation), etc.;
	\item Krylov subspace method: CG~(conjugate gradient), GMRES~(generalized minimal residual), etc.;
	\item multigrid method.
\end{enumerate}

\paragraph{Classical method}
Suppose $P$ is easy to invert, let $A = P+A-P$, then
\begin{equation*}
Ax=b \quad \Leftrightarrow \quad Px = (P-A)x + b.
\end{equation*} 
$P = diag(A)$ gives us Jacobian method, and it's GPU-friendly; $P = lower(A)$ gives us GS method; $P = diag(A) + w\cdot lower(A)$ gives us SOR method where $w<2$.

The residual term follows
\begin{equation*}
r_k \equiv A(x^\star - x_k) = b - Ax_k \quad \Leftrightarrow \quad r_{k+1} = (I-P^{-1}A)r_k.
\end{equation*}
To make classical method converge, we need $\rho(I - P^{-1}A) < 1$, where $\rho(\cdot)$ is the spectrum radius.

\paragraph{Krylov subpace method}
\begin{note}
	A good reference on CG: \texttt{An Introduction to the Conjugate Gradient Method 	Without the Agonizing Pain} by J. Shewchuk.
\end{note}
Assuming $A^\trans = A$ and $A \succeq 0$.

\section{Elastic Materials and Finite Element Simulation}

\section{Something more...}

\section{Papers and books}
\begin{enumerate}
	\item Nonlinear Continuum Mechanics for Finite Element Analysis by J. Bonet
	\item Convex optimization by S. Boyd
	\item Numerical optimization by Nocedal
\end{enumerate}

\end{document}